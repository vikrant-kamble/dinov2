{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slimtp.modules import AMDataset\n",
    "from slimtp.pipelines import AMPreprocessing\n",
    "from torch.utils.data import DataLoader\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from pj_cape_foundation_eval.models.dino_embedding_creator import DinoEmbeddingCreator, build_model_for_eval\n",
    "from dinov2.configs import dinov2_default_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import torch\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = omegaconf.OmegaConf.load(\"./configs/config.yaml\")\n",
    "ampreproc = AMPreprocessing(data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "======== Stage AMPreprocessing ========\n",
      "[2023-12-19 04:17:30][slimtp.lib.common.boston][WARNING] - Query Error! return None value, error Msg: (404, 'Request failed: {\\n  \"ErrorMsg\": \"failed fetching tiles: fetch failed: tsdata=source = shower_v2, survey = 1620937 tile=(284324, 415742, 20): fetch failed: 404: Tile not found\",\\n  \"ErrorCode\": 404,\\n  \"PartialResponse\": null\\n}\\n\\n')\n",
      "100%|██████████| 10/10 [00:00<00:00, 54.18it/s]\n",
      "[2023-12-19 04:17:30][slimtp.pipelines.am_preprocessing][WARNING] - Drop 1 uncacheable samples.\n",
      "/root/cape/capelibs/mtp/slimtp/lib/data.py:206: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['geometry', 'imagery_source', 'split', 'use', 'cache_key'], dtype='object')]\n",
      "\n",
      "  df.to_hdf(path, key=\"data\", mode=\"w\")\n"
     ]
    }
   ],
   "source": [
    "ampreproc.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geometry          b\"\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00C\\x00\\x0...\n",
       "imagery_source    sv2:nearmap_vertical_jpg:ffd055ee-e430-11e8-b9...\n",
       "imagery_date                              2018-10-26 00:00:00+00:00\n",
       "split                                                          test\n",
       "use                                                            test\n",
       "identifier                                                        0\n",
       "cache_key         {'source': 'shower_v2', 'imagery_source': 'sv2...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_hdf(\"/cnvrg/output/preprocessing/data.h5\")\n",
    "df['cache_key'] = df['cache_key'].apply(eval)\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DinoInferenceDataset(AMDataset):\n",
    "    def __getitem__(self, index: int):\n",
    "        item = self.get_df_data(index)\n",
    "        sample_name = item[\"identifier\"]\n",
    "        x_clean = self.get_aug_item(item, self.t_clean)\n",
    "        return x_clean, sample_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Inference dataset\n",
    "amdataset = DinoInferenceDataset(config=data_config, df=df)\n",
    "\n",
    "# Create torch dataloader\n",
    "data_loader = DataLoader(amdataset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cape-ml-projects-data/data_stores/dinov2/experiments/a100x4/DIN-145/eval/training_324999/teacher_checkpoint.pth...\n",
      "/ [1 files][  1.5 GiB/  1.5 GiB]   44.5 MiB/s                                   \n",
      "Operation completed over 1 objects/1.5 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "# Download checkpointb\n",
    "checkpoint_path = \"./data/teacher_checkpoint.pth\"\n",
    "\n",
    "# Only run the below command if the above path doesn't exist\n",
    "# !gsutil cp 'gs://cape-ml-projects-data/data_stores/dinov2/experiments/a100x4/DIN-145/eval/training_324999/teacher_checkpoint.pth' $checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download config corresponding to this checkpoint\n",
    "config_path = \"./data/teacher_config.yaml\"\n",
    "\n",
    "# Only run the below command if the above path doesn't exist\n",
    "# !gsutil cp 'gs://cape-ml-projects-data/data_stores/dinov2/experiments/a100x4/DIN-145/config.yaml' $config_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 0it [05:27, ?it/s]\n",
      "Take key teacher in provided checkpoint dict\n",
      "Pretrained weights found at ./data/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v', 'ibot_head.mlp.0.weight', 'ibot_head.mlp.0.bias', 'ibot_head.mlp.2.weight', 'ibot_head.mlp.2.bias', 'ibot_head.mlp.4.weight', 'ibot_head.mlp.4.bias', 'ibot_head.last_layer.weight_g', 'ibot_head.last_layer.weight_v'])\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "default_cfg = OmegaConf.create(dinov2_default_config)\n",
    "\n",
    "new_config = OmegaConf.load(config_path)\n",
    "cfg = OmegaConf.merge(default_cfg, new_config)\n",
    "\n",
    "backbone_model = build_model_for_eval(cfg, checkpoint_path, cuda=True)\n",
    "dino_model = DinoEmbeddingCreator(backbone_model=backbone_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    log_every_n_steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = dino_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  3.70it/s]\n"
     ]
    }
   ],
   "source": [
    "results = trainer.predict(dino_model, dataloaders=data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4636, -2.2672,  1.0947,  ...,  0.2755, -0.2878,  0.0938],\n",
       "         [ 0.4437,  0.2556, -0.1204,  ...,  0.2766, -0.0068,  0.2490],\n",
       "         [-0.2920,  0.6529,  1.0361,  ...,  0.1713,  0.3475,  0.1404],\n",
       "         [-0.0382, -0.8151, -0.0095,  ...,  0.1934, -0.0895,  0.5180],\n",
       "         [ 0.0240, -0.6696, -1.9730,  ...,  0.0438, -0.4117, -0.0673]]),\n",
       " tensor([0, 1, 2, 3, 4]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.cat([r[0] for r in results], 0).cpu().numpy()\n",
    "identifiers = np.concatenate([list(r[1]) for r in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = pd.DataFrame(embeddings, index=identifiers,\n",
    " columns=[f\"emb_{i}\" for i in range(embeddings.shape[1])])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

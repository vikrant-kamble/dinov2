{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cnvrgv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from data_science_tools.core.utils.io import within_directory\n",
    "from data_science_tools.datasets import AttrGeomSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch embeddings - these were generated as part of a Cnvrg experiment\n",
    "cnvrg = cnvrgv2.Cnvrg()\n",
    "\n",
    "my_proj = cnvrg.projects.get(\"dinov2_living_area\")\n",
    "experiment = my_proj.experiments.get(\"lgtt3jv7hbdv8oz1gpe4\")\n",
    "\n",
    "with within_directory(\"./data/\"):\n",
    "    if not os.path.exists(\"./output/inference\"):\n",
    "        experiment.pull_artifacts(wait_until_success=True, poll_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataframe containing the embeddings for all living area datasets.\n",
    "inference_df = pd.read_hdf(\"./data/output/inference/output_tensors.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = [\"geometry\", \"imagery_source\", \"imagery_date\", \"split\"]\n",
    "\n",
    "# add columns of the dataframe that include the embeddings\n",
    "embedding_columns = [col for col in inference_df.columns if \"emb\" in col]\n",
    "columns_to_use.extend(embedding_columns)\n",
    "\n",
    "df = inference_df[columns_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to GCP - run only once\n",
    "# df.to_parquet(\"gs://cape-ml-projects-data/pj_living_area_dev_v5/dinov2_living_area_embeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df[\"split\"] == \"ta_mls_train\"]\n",
    "df_test = df[df[\"split\"] == \"ta_mls_test\"]\n",
    "\n",
    "df_eval = df[df[\"split\"] == \"cubicasa_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the targets, we need to fetch the AttrGeomSets\n",
    "ta_mls_train_mnemonic = \"living_area_v3/20220331_cnn_train_all\"\n",
    "ta_mls_test_mnemonic = \"living_area_v3/20220331_cnn_test_all\"\n",
    "cubicasa_test_mneomonic = \"pj_living_area_dev_v5/20231115_cubicasa_ortho_survey_id_test\"\n",
    "\n",
    "ta_mls_train_ds = AttrGeomSet.from_mnemonic(ta_mls_train_mnemonic)\n",
    "ta_mls_test_ds = AttrGeomSet.from_mnemonic(ta_mls_test_mnemonic)\n",
    "cubicasa_test_ds = AttrGeomSet.from_mnemonic(cubicasa_test_mneomonic)\n",
    "\n",
    "ta_mls_train_df = ta_mls_train_ds.to_pandas()\n",
    "ta_mls_train_df = ta_mls_train_df[['geometry', 'imagery_source', 'imagery_date', 'gla_sqft']]\n",
    "ta_mls_train_df[\"gla_target\"] = ta_mls_train_df[\"gla_sqft\"]\n",
    "\n",
    "ta_mls_test_df = ta_mls_test_ds.to_pandas()\n",
    "ta_mls_test_df = ta_mls_test_df[['geometry', 'imagery_source', 'imagery_date', 'gla_sqft']]\n",
    "ta_mls_test_df[\"gla_target\"] = ta_mls_test_df[\"gla_sqft\"]\n",
    "\n",
    "cubicasa_test_df = cubicasa_test_ds.to_pandas()\n",
    "cubicasa_test_df = cubicasa_test_df[['geometry', 'imagery_source', 'imagery_date', 'gla_target']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.merge(ta_mls_train_df, on=[\"geometry\", \"imagery_source\", \"imagery_date\"])\n",
    "df_test = df_test.merge(ta_mls_test_df, on=[\"geometry\", \"imagery_source\", \"imagery_date\"])\n",
    "\n",
    "df_eval = df_eval.merge(cubicasa_test_df, on=[\"geometry\", \"imagery_source\", \"imagery_date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23705, 2054)\n"
     ]
    }
   ],
   "source": [
    "df_train_use = df_train.sample(frac=0.1, random_state=42)\n",
    "print(df_train_use.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_use_train, df_use_val = train_test_split(df_train_use, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_use_train[embedding_columns].to_numpy()\n",
    "y_train = df_use_train[\"gla_target\"].to_numpy()\n",
    "\n",
    "# For choosing the best model during a single training run\n",
    "# and for preventing overfitting\n",
    "x_val = df_use_val[embedding_columns].to_numpy()\n",
    "y_val = df_use_val[\"gla_target\"].to_numpy()\n",
    "\n",
    "# For chossing the best hyperparam model\n",
    "x_test = df_test[embedding_columns].to_numpy()\n",
    "y_test = df_test[\"gla_target\"].to_numpy()\n",
    "\n",
    "# Only for final evaluation\n",
    "x_eval = df_eval[embedding_columns].to_numpy()\n",
    "y_eval = df_eval[\"gla_target\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    verbose=100,\n",
    "    random_state=42,\n",
    "    loss_function=\"MAE\",\n",
    "    use_best_model=True,\n",
    "    eval_metric=\"MAE\",\n",
    "    early_stopping_rounds=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 644.8835828\ttest: 639.6064451\tbest: 639.6064451 (0)\ttotal: 246ms\tremaining: 4m 5s\n",
      "100:\tlearn: 417.3160551\ttest: 424.4096615\tbest: 424.4096615 (100)\ttotal: 18.5s\tremaining: 2m 45s\n",
      "200:\tlearn: 381.5169575\ttest: 396.8859329\tbest: 396.8859329 (200)\ttotal: 37.5s\tremaining: 2m 28s\n",
      "300:\tlearn: 364.0827707\ttest: 386.1006790\tbest: 386.1006790 (300)\ttotal: 55.9s\tremaining: 2m 9s\n",
      "400:\tlearn: 349.8105586\ttest: 379.5393160\tbest: 379.5393160 (400)\ttotal: 1m 13s\tremaining: 1m 49s\n",
      "500:\tlearn: 337.4981752\ttest: 374.8832350\tbest: 374.8832350 (500)\ttotal: 1m 30s\tremaining: 1m 29s\n",
      "600:\tlearn: 327.3635953\ttest: 371.7029401\tbest: 371.7029401 (600)\ttotal: 1m 47s\tremaining: 1m 11s\n",
      "700:\tlearn: 319.0723615\ttest: 369.5948568\tbest: 369.5948568 (700)\ttotal: 2m 4s\tremaining: 52.9s\n",
      "800:\tlearn: 311.9754143\ttest: 368.0950492\tbest: 368.0950492 (800)\ttotal: 2m 21s\tremaining: 35s\n",
      "900:\tlearn: 305.3810969\ttest: 366.9314345\tbest: 366.9314345 (900)\ttotal: 2m 37s\tremaining: 17.3s\n",
      "999:\tlearn: 299.6257890\ttest: 365.7733738\tbest: 365.7733738 (999)\ttotal: 2m 54s\tremaining: 0us\n",
      "\n",
      "bestTest = 365.7733738\n",
      "bestIteration = 999\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7fd6e7f8d340>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(x_train, y_train, eval_set=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transmo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpj_living_area_dev_v5\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransmo_development\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcatboost_metrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics_factory\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pj_living_area_dev_v5/transmo_development/utils/catboost_metrics.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Catboost metrics for training.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransmo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcatboost_metrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     MetricsFactory,\n\u001b[1;32m      5\u001b[0m     UnderestimateMetric,\n\u001b[1;32m      6\u001b[0m     UserDefinedMetric_ppe10,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m metrics_factory \u001b[38;5;241m=\u001b[39m MetricsFactory()\n\u001b[1;32m     10\u001b[0m metrics_factory\u001b[38;5;241m.\u001b[39mregister_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transmo'"
     ]
    }
   ],
   "source": [
    "from pj_living_area_dev_v5.transmo_development.utils.catboost_metrics import metrics_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

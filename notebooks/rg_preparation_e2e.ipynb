{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6c41971-c60a-4f3d-800b-4047a2a686c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "nearmap_df_1 = pd.read_parquet(\"/data/finetune_mtmv_nearmap_rg/chipping/chips/dataset.parquet\")\n",
    "nearmap_df_1[\"chips_path\"] = \"/data/finetune_mtmv_nearmap_rg/chipping/chips\"\n",
    "nearmap_df_2 = pd.read_parquet(\"/data/evaluate_mtmv_nearmap_rg/chips/dataset.parquet\")\n",
    "nearmap_df_2[\"chips_path\"] = \"/data/evaluate_mtmv_nearmap_rg/chips\"\n",
    "\n",
    "# /data/evaluate_mtmv_nearmap_rg and /data/evaluate_mtmv_nearmap_rg are old rg test and train sets (multiple worker votes) from these aws cnvrg datasets:\n",
    "# gs://cape-ml-historical-data/202307_aws_cnvrg_datasets/evaluate_mtmv_nearmap_rg\n",
    "# gs://cape-ml-historical-data/202307_aws_cnvrg_datasets/finetune_mtmv_nearmap_rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf20b50-ef81-4c23-82f6-a26d5a93d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def majority_vote(vote_list):\n",
    "    \"\"\"Probably the 1,000th implementation of majority vote at cape.\n",
    "    But this is a pretty fast one, with random tie-breaking.\n",
    "    \"\"\"\n",
    "    counter = Counter(vote_list)\n",
    "    return random.choice([x for x in counter if counter[x] == max(counter.values())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2d99caf-2f5c-428b-8d72-643a17173dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = nearmap_df_1\n",
    "columns_to_keep = [\"geometry\", \"imagery_source\", \"imagery_date\"]\n",
    "\n",
    "groupby = \"geometry_id\"\n",
    "if groupby is not None and groupby not in columns_to_keep:\n",
    "    columns_to_keep.append(groupby)\n",
    "\n",
    "# group votes, keep only required columns\n",
    "if \"geometry_labels\" in df.columns:\n",
    "\n",
    "    # Labeled dataset. Let's aggregate:\n",
    "\n",
    "    cols_aggregations = {\"geometry_labels\": list}\n",
    "    # If this dataset contains many votes, keep them\n",
    "    if \"label_vote_id\" in df.columns:\n",
    "        cols_aggregations[\"label_vote_id\"] = list\n",
    "\n",
    "    # Keep a few columns for bedrock datasets\n",
    "    for col in [\"cache_key\", \"dataset_path\", \"dataset_format\", \"filename\", \"chips_path\"]:\n",
    "        if col in df.columns:\n",
    "            # Keep first\n",
    "            cols_aggregations[col] = \"first\"  # type: ignore\n",
    "\n",
    "    df = df.groupby(columns_to_keep)[list(cols_aggregations.keys())].agg(cols_aggregations).reset_index()\n",
    "    df.geometry_labels = df.geometry_labels.apply(lambda x: majority_vote(x))\n",
    "    df = df.drop(columns=\"label_vote_id\")\n",
    "X_train_nearmap = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e9aa07-8927-4f19-88b6-ad50f088c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = nearmap_df_2\n",
    "columns_to_keep = [\"geometry\", \"imagery_source\", \"imagery_date\"]\n",
    "\n",
    "groupby = \"geometry_id\"\n",
    "if groupby is not None and groupby not in columns_to_keep:\n",
    "    columns_to_keep.append(groupby)\n",
    "\n",
    "# group votes, keep only required columns\n",
    "if \"geometry_labels\" in df.columns:\n",
    "\n",
    "    # Labeled dataset. Let's aggregate:\n",
    "\n",
    "    cols_aggregations = {\"geometry_labels\": list}\n",
    "    # If this dataset contains many votes, keep them\n",
    "    if \"label_vote_id\" in df.columns:\n",
    "        cols_aggregations[\"label_vote_id\"] = list\n",
    "\n",
    "    # Keep a few columns for bedrock datasets\n",
    "    for col in [\"cache_key\", \"dataset_path\", \"dataset_format\", \"filename\", \"chips_path\"]:\n",
    "        if col in df.columns:\n",
    "            # Keep first\n",
    "            cols_aggregations[col] = \"first\"  # type: ignore\n",
    "\n",
    "    df = df.groupby(columns_to_keep)[list(cols_aggregations.keys())].agg(cols_aggregations).reset_index()\n",
    "    df.geometry_labels = df.geometry_labels.apply(lambda x: majority_vote(x))\n",
    "    df = df.drop(columns=\"label_vote_id\")\n",
    "X_val_nearmap = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77220c58-554b-4874-9190-392307ff87b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43968"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_nearmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff966c8d-db93-4b7a-a89b-cb8894a72579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11562"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val_nearmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43c4bf14-73ea-460a-9b1c-964d386fa9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_labels = list(X_train_nearmap[\"geometry_labels\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9edf8049-4390-4c81-83b5-ecedc5e42339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_dir = \"/cnvrg/rg_evaluation/train\"\n",
    "for label in rg_labels:\n",
    "    os.makedirs(os.path.join(base_dir, label), exist_ok=True)\n",
    "\n",
    "base_dir = \"/cnvrg/rg_evaluation/val\"\n",
    "for label in rg_labels:\n",
    "    os.makedirs(os.path.join(base_dir, label), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "202c1c36-a182-4942-839a-6c61cc498d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['geometry', 'imagery_source', 'imagery_date', 'geometry_id',\n",
       "       'geometry_labels', 'filename', 'chips_path'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_nearmap.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3372f02a-8379-4cb9-ab12-c4f78650dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_val_nearmap\n",
    "\n",
    "dataset_path = \"/cnvrg/rg_evaluation/val\"\n",
    "\n",
    "for single_file, pred, chips_dir in zip(X.filename, X.geometry_labels, X.chips_path):\n",
    "    image_full_path = os.path.join(chips_dir, single_file)\n",
    "    filename = image_full_path.split(\"/\")[-1]   \n",
    "    os.symlink(image_full_path, os.path.join(dataset_path, pred, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b10d1ab4-2181-413f-8607-ffee1ac810f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_nearmap\n",
    "\n",
    "dataset_path = \"/cnvrg/rg_evaluation/train\"\n",
    "\n",
    "for single_file, pred, chips_dir in zip(X.filename, X.geometry_labels, X.chips_path):\n",
    "    image_full_path = os.path.join(chips_dir, single_file)\n",
    "    filename = image_full_path.split(\"/\")[-1]   \n",
    "    os.symlink(image_full_path, os.path.join(dataset_path, pred, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e06d297-f3e3-4ec3-a6de-d493a769e2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "root = \"/cnvrg\"\n",
    "dataset = \"rg_evaluation\"\n",
    "\n",
    "out_dataset = f\"{dataset}_imagenet\"\n",
    "shutil.rmtree(f\"{root}/{out_dataset}\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6e8d804-906c-46c2-8399-073961f6ca56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n00000000': 'flat',\n",
       " 'n00000001': 'gable',\n",
       " 'n00000002': 'hip',\n",
       " 'n00000003': 'mixed_w_wind_credit',\n",
       " 'n00000004': 'mixed_wo_wind_credit',\n",
       " 'n00000005': 'unknown'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(f\"{root}/{dataset}/train/**/*.png\", recursive=True)\n",
    "all_labels = set(\n",
    "    [\n",
    "        x.split(os.path.sep)[-2] for x in files\n",
    "    ]\n",
    ")\n",
    "all_labels = {f\"n{i:08d}\": l for i, l in enumerate(sorted(all_labels))}\n",
    "all_labels_i = {v:k for k,v in all_labels.items()}\n",
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4aa5a7a-e07f-451c-8a47-0938b548a6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"{root}/{out_dataset}/train\", exist_ok=True)\n",
    "os.makedirs(f\"{root}/{out_dataset}/val\", exist_ok=True)\n",
    "\n",
    "with open(f\"{root}/{out_dataset}/labels.txt\", \"w+\") as fp:\n",
    "    for i, l in all_labels.items():\n",
    "        fp.write(f\"{i},{l}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "111d3a3c-2ea3-46b7-8e24-bbb96f4221d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, f in enumerate(files):\n",
    "    split, class_label, filename = f.split(os.path.sep)[-3:]\n",
    "\n",
    "    assert split in ['train', 'val', 'test'], f\"{split} not a split\"\n",
    "\n",
    "    assert class_label in all_labels.values()\n",
    "\n",
    "    d = f\"{root}/{out_dataset}/{split}/{all_labels_i[class_label]}\"\n",
    "\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "    os.symlink(f, f\"{d}/{all_labels_i[class_label]}_{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98798770-2526-4b13-8907-0f004eb15f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(f\"{root}/{dataset}/val/**/*.png\", recursive=True)\n",
    "for i, f in enumerate(files):\n",
    "    split, class_label, filename = f.split(os.path.sep)[-3:]\n",
    "\n",
    "    assert split in ['train', 'val', 'test'], f\"{split} not a split\"\n",
    "\n",
    "    assert class_label in all_labels.values()\n",
    "\n",
    "    d = f\"{root}/{out_dataset}/{split}/{all_labels_i[class_label]}\"\n",
    "\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "    os.symlink(f, f\"{d}/{all_labels_i[class_label]}_{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6109aaa-123e-4776-9a0c-165f5cedfb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/cnvrg\"\n",
    "\n",
    "out_dataset = f\"{dataset}_imagenet\"\n",
    "from dinov2.data.datasets import ImageNet\n",
    "for split in [ImageNet.Split.TRAIN, ImageNet.Split.VAL]:\n",
    "    dataset = ImageNet(split=split, root=f\"{root}/{out_dataset}\", extra=f\"{root}/{out_dataset}\")\n",
    "    dataset.dump_extra()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5ea365b-f625-479a-bde2-016cbc236e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file count train: 43968\n",
      "file count val: 11562\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "count = 0\n",
    "for root_dir, cur_dir, files in os.walk(r'/cnvrg/rg_evaluation_imagenet/train'):\n",
    "    count += len(files)\n",
    "print('file count train:', count)\n",
    "count = 0\n",
    "for root_dir, cur_dir, files in os.walk(r'/cnvrg/rg_evaluation_imagenet/val'):\n",
    "    count += len(files)\n",
    "print('file count val:', count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
